{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**GENAI HANDSON**\\\n",
        "\n",
        "ADVANCED PROMPT ENG\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "NAME:SVOJAS A \\\n",
        "SRN: PES2UG23CS633\\\n",
        "SECTION: J\n"
      ],
      "metadata": {
        "id": "MH457XODjJAv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ.pop(\"GROQ_API_KEY\", None)\n",
        "os.environ.pop(\"GOOGLE_API_KEY\", None)\n",
        "\n",
        "print(\"Environment cleared.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRlvDcKYAzm3",
        "outputId": "254698cc-c26c-40e4-cf5e-c223741848fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Environment cleared.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1cTK7diAYra",
        "outputId": "ae112db7-089a-4df1-ce39-04f9640a1a99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/111.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.7/111.7 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/500.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m491.5/500.5 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m500.5/500.5 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/158.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.1/158.1 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q --upgrade langchain langchain-groq\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import getpass\n",
        "from langchain_groq import ChatGroq\n",
        "\n",
        "# IMPORTANT: Must start with gsk_\n",
        "os.environ[\"GROQ_API_KEY\"] = getpass.getpass(\"Enter your GROQ API Key: \")\n",
        "\n",
        "llm = ChatGroq(\n",
        "    model=\"llama-3.1-8b-instant\",\n",
        "    temperature=0.0\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vS6VMBGAn2E",
        "outputId": "e73b5404-e53b-430b-ace9-64ae6be4f48e"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your GROQ API Key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import getpass\n",
        "from langchain_groq import ChatGroq\n",
        "\n",
        "os.environ[\"GROQ_API_KEY\"] = getpass.getpass(\"Enter GROQ key (must start with gsk_): \")\n",
        "\n",
        "llm = ChatGroq(\n",
        "    model=\"llama-3.1-8b-instant\",\n",
        "    temperature=0.0\n",
        ")\n",
        "\n",
        "print(llm.invoke(\"Say hello\").content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QvDfJvriCUm",
        "outputId": "169b3638-4663-4122-9f00-85f0ae876291"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter GROQ key (must start with gsk_): ··········\n",
            "Hello. How can I assist you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Roger has 5 tennis balls. He buys 2 more cans of tennis balls. Each can has 3 tennis balls. How many does he have now?\"\n"
      ],
      "metadata": {
        "id": "Z9-f8deGirQv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_standard = f\"Answer this question: {question}\"\n",
        "\n",
        "print(\"STANDARD:\")\n",
        "print(llm.invoke(prompt_standard).content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "niXHiFzGitdM",
        "outputId": "36b77a60-3f3e-40cd-9889-ef4b0ae4fc5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "STANDARD:\n",
            "To find out how many tennis balls Roger has now, we need to add the initial number of tennis balls he had (5) to the number of tennis balls he bought (2 cans * 3 tennis balls per can).\n",
            "\n",
            "2 cans * 3 tennis balls per can = 6 tennis balls\n",
            "\n",
            "Now, let's add the initial number of tennis balls (5) to the number of tennis balls he bought (6):\n",
            "\n",
            "5 + 6 = 11\n",
            "\n",
            "So, Roger now has 11 tennis balls.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_cot = f\"Answer this question. Let's think step by step. {question}\"\n",
        "\n",
        "print(\"\\nCHAIN OF THOUGHT:\")\n",
        "print(llm.invoke(prompt_cot).content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCOQwJXKivmg",
        "outputId": "3b30bfb6-7512-4968-ec8e-5389e9e4301c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "CHAIN OF THOUGHT:\n",
            "To find out how many tennis balls Roger has now, we need to follow these steps:\n",
            "\n",
            "1. Roger already has 5 tennis balls.\n",
            "2. He buys 2 more cans of tennis balls. Each can has 3 tennis balls, so he buys 2 x 3 = 6 more tennis balls.\n",
            "3. Now, we add the tennis balls he already had (5) to the new tennis balls he bought (6). 5 + 6 = 11\n",
            "\n",
            "So, Roger now has 11 tennis balls.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnableParallel, RunnableLambda\n",
        "from langchain_core.output_parsers import StrOutputParser\n"
      ],
      "metadata": {
        "id": "SjksWG5BiyPH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "problem = \"How can I get my 5-year-old to eat vegetables?\"\n"
      ],
      "metadata": {
        "id": "SOOq6LZyi0c6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_branch = ChatPromptTemplate.from_template(\n",
        "    \"Problem: {problem}. Give one unique creative solution. Solution {id}:\"\n",
        ")\n",
        "\n",
        "branches = RunnableParallel(\n",
        "    sol1=prompt_branch.partial(id=\"1\") | llm | StrOutputParser(),\n",
        "    sol2=prompt_branch.partial(id=\"2\") | llm | StrOutputParser(),\n",
        "    sol3=prompt_branch.partial(id=\"3\") | llm | StrOutputParser(),\n",
        ")\n"
      ],
      "metadata": {
        "id": "y4bz5D5ci2eF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_judge = ChatPromptTemplate.from_template(\"\"\"\n",
        "I have three solutions for '{problem}':\n",
        "\n",
        "1. {sol1}\n",
        "2. {sol2}\n",
        "3. {sol3}\n",
        "\n",
        "Act as a child psychologist. Choose the most sustainable (not bribery) and explain why.\n",
        "\"\"\")\n"
      ],
      "metadata": {
        "id": "ra-9ho9Bi4hY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tot_chain = (\n",
        "    RunnableParallel(problem=RunnableLambda(lambda x: x), branches=branches)\n",
        "    | (lambda x: {**x[\"branches\"], \"problem\": x[\"problem\"]})\n",
        "    | prompt_judge\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "print(\"\\nTREE OF THOUGHT RESULT:\")\n",
        "print(tot_chain.invoke(problem))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8dzxCKqi7JJ",
        "outputId": "9ec4ee33-d307-4141-d801-3f499db27e08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TREE OF THOUGHT RESULT:\n",
            "As a child psychologist, I would recommend **Solution 2: \"Veggie Gardening\"** as the most sustainable approach to encourage a 5-year-old to eat vegetables. Here's why:\n",
            "\n",
            "1. **Ownership and responsibility**: By involving your child in the process of growing their own vegetables, they develop a sense of ownership and responsibility. This can lead to a deeper appreciation for the food they eat and a willingness to try new vegetables.\n",
            "2. **Hands-on learning**: Gardening and cooking are hands-on activities that allow your child to learn about the process of growing and preparing food. This experiential learning can help them develop a deeper understanding of the food they eat and its nutritional value.\n",
            "3. **Development of healthy habits**: By involving your child in the process of growing and preparing their own food, you can help them develop healthy eating habits that will last a lifetime. This approach encourages them to try new foods, experiment with different flavors and textures, and develop a positive relationship with food.\n",
            "4. **Long-term benefits**: The benefits of \"Veggie Gardening\" extend beyond mealtime. By teaching your child about the process of growing and preparing food, you can help them develop essential life skills, such as problem-solving, critical thinking, and self-sufficiency.\n",
            "5. **No reliance on external motivators**: Unlike the \"Veggie Face\" approach, which relies on external motivators like games and rewards, \"Veggie Gardening\" encourages your child to develop a genuine interest in vegetables and healthy eating habits.\n",
            "\n",
            "While the \"Veggie Face\" approach can be a fun and engaging way to introduce new vegetables to your child, it may not be as sustainable in the long term. Children may eventually lose interest in the game, and the reliance on external motivators can create unhealthy associations with food.\n",
            "\n",
            "In contrast, \"Veggie Gardening\" encourages your child to develop a deeper appreciation for the food they eat and a willingness to try new vegetables. By involving your child in the process of growing and preparing their own food, you can help them develop healthy eating habits that will last a lifetime.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_draft = ChatPromptTemplate.from_template(\n",
        "    \"Write a 1-sentence movie plot about: {topic}. Genre: {genre}.\"\n",
        ")\n",
        "\n",
        "drafts = RunnableParallel(\n",
        "    draft_scifi=prompt_draft.partial(genre=\"Sci-Fi\") | llm | StrOutputParser(),\n",
        "    draft_romance=prompt_draft.partial(genre=\"Romance\") | llm | StrOutputParser(),\n",
        "    draft_horror=prompt_draft.partial(genre=\"Horror\") | llm | StrOutputParser(),\n",
        ")\n"
      ],
      "metadata": {
        "id": "cl-oJPEci9h8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_combine = ChatPromptTemplate.from_template(\"\"\"\n",
        "Topic: {topic}\n",
        "\n",
        "Sci-Fi: {draft_scifi}\n",
        "Romance: {draft_romance}\n",
        "Horror: {draft_horror}\n",
        "\n",
        "Create one paragraph combining technology, passion, and fear.\n",
        "\"\"\")\n"
      ],
      "metadata": {
        "id": "1ZQ68CO0i_h7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "got_chain = (\n",
        "    RunnableParallel(topic=RunnableLambda(lambda x: x), drafts=drafts)\n",
        "    | (lambda x: {**x[\"drafts\"], \"topic\": x[\"topic\"]})\n",
        "    | prompt_combine\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "print(\"\\nGRAPH OF THOUGHT RESULT:\")\n",
        "print(got_chain.invoke(\"Time Travel\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KK4piAIdjBw5",
        "outputId": "67715aec-c6b8-439b-8f50-8b039c39f136"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "GRAPH OF THOUGHT RESULT:\n",
            "As Dr. Emma Taylor stood at the controls of her time machine, a fusion of quantum physics and artificial intelligence, she felt the rush of adrenaline coursing through her veins. The sleek, metallic device hummed to life, its holographic display flashing with a countdown to the moment she had been waiting for - a chance to relive the pivotal night that had changed her life forever. But as she set the coordinates and initiated the sequence, a chill ran down her spine. She had been warned about the risks of meddling with the timeline, and the eerie feeling that she was being watched by unseen eyes only added to her growing sense of unease. And yet, she couldn't resist the allure of reuniting with her lost love, Jack, who had been torn from her life by a cruel twist of fate. As the machine whirred to life, Emma felt her heart pounding in her chest, and a whispered warning echoed in her mind: \"Be careful what you wish for, for in the world of time travel, the past is not always what it seems.\"\n"
          ]
        }
      ]
    }
  ]
}